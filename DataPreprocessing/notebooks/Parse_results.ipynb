{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'movielens'\n",
    "file_name = 'results_llama3_collaborative_2steps'\n",
    "all_items = False\n",
    "domain = {\n",
    "    'lastfm': 'music',\n",
    "    'dbbook': 'book',\n",
    "    'movielens': 'movie'\n",
    "}[dataset]\n",
    "import os\n",
    "datapath = os.path.join('..', 'data', dataset)\n",
    "if all_items:\n",
    "    out_file = {\n",
    "        'results_llama3_text_all_items': f'predicted_score_LLaMA_{domain.capitalize()}_text_all_items',\n",
    "        'results_llama3_no_kn_all_items': f'predicted_score_LLaMA_{domain.capitalize()}_no_kn_all_items',\n",
    "        'results_llama3_kgraph_all_items': f'predicted_score_LLaMA_{domain.capitalize()}_graph_all_items',\n",
    "        'results_llama3_chat_model_all_items': f'predicted_score_LLaMA_{domain.capitalize()}_chat_all_items',\n",
    "        'results_llama3_graph_text_all_items': f'predicted_score_LLaMA_{domain.capitalize()}_graph_text_all_items',\n",
    "        'results_llama3_collaborative_all_items': f'predicted_score_LLaMA_{domain.capitalize()}_collaborative_all_items',\n",
    "    }[file_name]\n",
    "else:\n",
    "    out_file = {\n",
    "        'results_llama3_adapted': f'predicted_score_LLaMA_{domain.capitalize()}_Text',\n",
    "        'results_llama3_adapted_no_kn': f'predicted_score_LLaMA_{domain.capitalize()}_no_kn',\n",
    "        'results_llama3_kgraph': f'predicted_score_LLaMA_{domain.capitalize()}_graph',\n",
    "        'results_llama3_chat_model': f'predicted_score_LLaMA_{domain.capitalize()}_chat',\n",
    "        'results_llama3_graph_text': f'predicted_score_LLaMA_{domain.capitalize()}_graph_text',\n",
    "        'results_llama3_collaborative': f'predicted_score_LLaMA_{domain.capitalize()}_collaborative',\n",
    "        'results_llama3_graph_text_double': f'predicted_score_LLaMA_{domain.capitalize()}_graph_text_double',\n",
    "        'results_llama3_collaborative_graph': f'predicted_score_LLaMA_{domain.capitalize()}_collaborative_graph',\n",
    "        'results_llama3_collaborative_graph_text': f'predicted_score_LLaMA_{domain.capitalize()}_collaborative_graph_text',\n",
    "        'results_llama3_collaborative_text': f'predicted_score_LLaMA_{domain.capitalize()}_collaborative_text',\n",
    "        'results_llama3_text_2steps': f'predicted_score_LLaMA_{domain.capitalize()}_Text_2steps',\n",
    "        'results_llama3_graph_2steps': f'predicted_score_LLaMA_{domain.capitalize()}_graph_2steps',\n",
    "        'results_llama3_collaborative_2steps': f'predicted_score_LLaMA_{domain.capitalize()}_collaborative_2steps',\n",
    "    }[file_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if all_items:\n",
    "    gt_df = pd.read_pickle(os.path.join(domain, f'{dataset}_test_dataset_all_items.pkl'))\n",
    "else:\n",
    "    gt_df = pd.read_pickle(os.path.join(domain, f'{dataset}_test_dataset.pkl'))\n",
    "gt_df['true_rank'] = gt_df['liked_resp'] + gt_df['disliked_resp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(domain, file_name+'.jsonl'), 'r') as json_file:\n",
    "    json_list = list(json_file)\n",
    "\n",
    "results = []\n",
    "for json_str in tqdm(json_list):\n",
    "   results.append(json.loads(json_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(results)\n",
    "res_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df['response'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_tsv_gt(row):\n",
    "    items = np.array(row['item'])\n",
    "    user = row['user']\n",
    "    like = items[[row['index_like_resp']]].tolist()[0]\n",
    "    dislike = items[[row['index_dislike_resp']]].tolist()[0]\n",
    "\n",
    "    list_items = []\n",
    "    for l in like:\n",
    "        list_items.append({\n",
    "            'user': user,\n",
    "            'item': l,\n",
    "            'score': 1\n",
    "        })\n",
    "\n",
    "    for d in dislike:\n",
    "        list_items.append({\n",
    "            'user': user,\n",
    "            'item': d,\n",
    "            'score': 0\n",
    "        })\n",
    "    return list_items\n",
    "\n",
    "gt_df['tsv_gt'] = gt_df.apply(get_tsv_gt, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "pd.DataFrame(list(itertools.chain(*gt_df['tsv_gt'].tolist()))).to_csv(os.path.join(domain, 'ground_truth.tsv'), index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = res_df.drop_duplicates(subset=['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(res_df), len(gt_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df['response'] = res_df['response'].apply(lambda x: x.split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_ranked_list(list_items):\n",
    "    ranked_list = []\n",
    "    for x in list_items[1:]:\n",
    "        numbers = re.findall('[0-9]+.', x)\n",
    "        try:\n",
    "            for rank in numbers[:1]:\n",
    "                name = re.sub(rank, '', x, 1).strip()\n",
    "                if len(name)>0:\n",
    "                    rank = [int(s) for s in re.findall(r'\\b\\d+\\b', rank)][0]\n",
    "                    ranked_list.append({'rank': rank, 'name': name})\n",
    "        except:\n",
    "            continue\n",
    "    return ranked_list\n",
    "\n",
    "res_df['ranked_list'] = res_df['response'].apply(get_ranked_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missing(row):\n",
    "    predicted = set([x['name'] for x in row['ranked_list']])\n",
    "    expected = set(row['true_rank'])\n",
    "    return {\n",
    "        'missing': expected-predicted,\n",
    "        '#missing': len(expected-predicted),\n",
    "        'added': predicted-expected,\n",
    "        '#added': len(predicted-expected)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = res_df.set_index('prompt').join(gt_df.set_index('prompt').loc[:, ['true_rank', 'user']]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df['missing_details'] = res_df.loc[:, [\"ranked_list\",\"true_rank\"]].apply(get_missing, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df['#missing'] = res_df['missing_details'].apply(lambda x: x['#missing'])\n",
    "res_df['#added'] = res_df['missing_details'].apply(lambda x: x['#added'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df['#missing'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df['#added'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(ranked_list):\n",
    "    ranked_list = sorted(ranked_list, key=lambda d: d['rank'])\n",
    "    try:\n",
    "        step = 1/len(ranked_list)\n",
    "    except:\n",
    "        step = 0\n",
    "    ranked_list = [{**x, **{'score': 1-step*i}} for i, x in enumerate(ranked_list)]\n",
    "    return ranked_list\n",
    "\n",
    "res_df['ranked_list'] = res_df['ranked_list'].apply(get_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset=='movielens':\n",
    "    def fix_title(title):\n",
    "        if \", The (\" in title:\n",
    "            name_film, _, year = title.rpartition(\", The (\")\n",
    "            title = \"The \" + name_film + \" (\" + year\n",
    "            return title\n",
    "        if \", A (\" in title:\n",
    "            name_film, _, year = title.rpartition(\", A (\")\n",
    "            title = \"A \" + name_film + \" (\" + year\n",
    "        return title\n",
    "    df_movies = pd.read_csv(os.path.join(datapath, r\"movies.dat\"), sep=\"::\", names=[\"item_id\", \"name\", \"geners\"], encoding='ISO-8859-1')\n",
    "    df_movies['name'] = df_movies['name'].apply(fix_title)\n",
    "    import re\n",
    "\n",
    "    df_relations = pd.read_csv(os.path.join(datapath, 'mapping_entities.tsv'), \\\n",
    "            names=['url', 'id_set'], sep='\\t')\n",
    "    dbpedia_mapping = pd.read_csv(os.path.join(datapath, 'MappingMovielens2DBpedia-1.2.tsv'), \\\n",
    "            names=['id_movie', 'name', 'dbpedia_url'], sep='\\t')\n",
    "    df_movies = dbpedia_mapping.set_index('dbpedia_url').join(df_relations.set_index('url')).reset_index()\n",
    "    df_movies['name'] = df_movies['name'].apply(lambda x: re.sub(\"\\s+\\(\\d+\\)$\", \"\", x))\n",
    "    df_movies['name'] = df_movies['name'].apply(lambda x: re.sub(r\"[^a-zA-Z0-9]+\", ' ', x).strip())\n",
    "    df_movies.dropna(inplace=True)\n",
    "    df_movies['id_set'] = df_movies['id_set'].astype(int)\n",
    "    mapping_dict = df_movies.loc[:, ['id_set', 'name']].set_index('id_set').to_dict()['name']\n",
    "    mapping_dict = {v:k for k, v in mapping_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset=='dbbook':\n",
    "    df_relations = pd.read_csv(os.path.join(datapath, 'mapping_entities.tsv'), sep='\\t')\n",
    "    df_relations['name'] = df_relations['uri'].apply(lambda x: x.split(\";\")[0])\n",
    "    mapping_dict = df_relations.set_index('id').to_dict()['name']\n",
    "    mapping_dict = {v:k for k, v in mapping_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "if dataset=='lastfm':\n",
    "    df_relations = pd.read_csv(os.path.join(datapath, 'mapping_items.tsv'), \\\n",
    "            names=['id', 'name'], sep='\\t')\n",
    "    mapping_dict = df_relations.set_index('id').to_dict()['name']\n",
    "    mapping_dict = {v:k for k, v in mapping_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baseline_format(row, mapping_dict):\n",
    "    tsv_list = []\n",
    "    user_id = row['user']\n",
    "    ranked_list = row['ranked_list']\n",
    "    for item in ranked_list:\n",
    "        if mapping_dict.get(item['name'], False) == False:\n",
    "            continue\n",
    "        tsv_list.append({\n",
    "            'user': int(user_id) if dataset not in ['boardgamegeek'] else user_id,\n",
    "            'item': mapping_dict[item['name']],\n",
    "            'score': item['score'],\n",
    "        })\n",
    "    return tsv_list\n",
    "\n",
    "res_df['tsv_list'] = res_df.apply(get_baseline_format, axis=1, mapping_dict=mapping_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "pd.DataFrame(list(itertools.chain(*res_df['tsv_list'].tolist()))).to_csv(os.path.join(domain, f'{out_file}.tsv'), index=False, sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inferenceEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
